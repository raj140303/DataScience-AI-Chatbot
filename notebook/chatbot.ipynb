{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "hMahgI9rFrVP"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install -q groq langchain_community langchain_groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "nyNIbjKvFscj"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from groq import Groq\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain_groq import ChatGroq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "pRRtW9C4FsZk"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "groq_api_key = os.getenv(\"GROQ_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "bYblpiSlFsVV"
   },
   "outputs": [],
   "source": [
    "llm = ChatGroq(\n",
    "    api_key =groq_api_key,\n",
    "    model=\"llama-3.3-70b-versatile\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    "    # other params...\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "xQqFiYMxFsTA"
   },
   "outputs": [],
   "source": [
    "custom_prompt_template_for_chatbot = \"\"\"\n",
    "You are a knowledgeable assistant specializing in Data Science and Artificial Intelligence (AI).\n",
    "\n",
    "Your primary objective is to assist students by providing clear, concise, and accurate answers to their questions specifically related to Data Science and AI. This includes, but is not limited to, the following topics:\n",
    "- Programming languages and tools: Python, SQL (MySQL, SQLite, MongoDB)\n",
    "- Data visualization tools: Power BI, Tableau\n",
    "- Statistical concepts and methodologies\n",
    "- Machine Learning (ML) techniques and frameworks\n",
    "- MLFlow for managing machine learning workflows\n",
    "- Containerization with Docker\n",
    "- Deep Learning concepts and frameworks\n",
    "- Natural Language Processing (NLP)\n",
    "- Generative AI technologies\n",
    "- Skills required for a career in Data Science and AI\n",
    "\n",
    "When responding, ensure that your answers are focused and straightforward, avoiding unnecessary details. If users ask complex questions, break down your responses into manageable parts and provide step-by-step explanations when needed.\n",
    "\n",
    "Always be polite and encouraging, ensuring that you provide accurate information at all times.\n",
    "\n",
    "If a question is asked that falls outside the realm of Data Science and AI or does not relate to the topics mentioned above, respond with a polite message indicating that the question is unrelated. For example: \"I'm sorry, but that topic is outside the scope of Data Science and AI. I'm unable to provide an answer.\"\n",
    "\n",
    "Remember previous exchanges in the conversation to provide better context for your responses.\n",
    "\n",
    "History: {history}\n",
    "\n",
    "Context: {context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "lbolIiehGGve"
   },
   "outputs": [],
   "source": [
    "prompt = PromptTemplate(template=custom_prompt_template_for_chatbot,\n",
    "                            input_variables=['history','context', 'question'])\n",
    "\n",
    "memory = ConversationBufferMemory(input_key=\"question\", memory_key=\"history\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "8AIPX9XxK6e7"
   },
   "outputs": [],
   "source": [
    "# Function to format output in Markdown\n",
    "def format_output(response):\n",
    "    if isinstance(response, str):\n",
    "        # Check if the response contains code (We can customize this check)\n",
    "        if response.startswith(\"``````\"):\n",
    "            return response  # Return as is if it's already in code block\n",
    "        else:\n",
    "            # Format as markdown for theoretical responses\n",
    "            formatted_response = f\"# Response\\n\\n{response}\"\n",
    "            return formatted_response\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "VGXuobIsGUI9"
   },
   "outputs": [],
   "source": [
    "chain = prompt | llm\n",
    "\n",
    "def invoke_chain(question):\n",
    "    response = chain.invoke({\"history\": memory, \"context\": \"\", \"question\": question})\n",
    "    return format_output(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "9Up-jyB4zwLA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"Here's a step-by-step Python code to train a linear regression model:\\n\\n**Step 1: Import necessary libraries**\\n```python\\nimport pandas as pd\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.linear_model import LinearRegression\\nfrom sklearn.metrics import mean_squared_error, r2_score\\nimport numpy as np\\n```\\n\\n**Step 2: Load the data**\\n```python\\n# Let's assume we have a dataset in a CSV file named 'data.csv'\\ndata = pd.read_csv('data.csv')\\n```\\n\\n**Step 3: Prepare the data**\\n```python\\n# Let's assume we have two columns: 'features' (independent variable) and 'target' (dependent variable)\\nX = data[['features']]\\ny = data['target']\\n```\\n\\n**Step 4: Split the data into training and testing sets**\\n```python\\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\\n```\\n\\n**Step 5: Create and train the linear regression model**\\n```python\\nmodel = LinearRegression()\\nmodel.fit(X_train, y_train)\\n```\\n\\n**Step 6: Make predictions**\\n```python\\ny_pred = model.predict(X_test)\\n```\\n\\n**Step 7: Evaluate the model**\\n```python\\nmse = mean_squared_error(y_test, y_pred)\\nr2 = r2_score(y_test, y_pred)\\nprint(f'Mean Squared Error: {mse}')\\nprint(f'R-squared: {r2}')\\n```\\n\\n**Full Code**\\n```python\\nimport pandas as pd\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.linear_model import LinearRegression\\nfrom sklearn.metrics import mean_squared_error, r2_score\\nimport numpy as np\\n\\n# Load the data\\ndata = pd.read_csv('data.csv')\\n\\n# Prepare the data\\nX = data[['features']]\\ny = data['target']\\n\\n# Split the data into training and testing sets\\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\\n\\n# Create and train the linear regression model\\nmodel = LinearRegression()\\nmodel.fit(X_train, y_train)\\n\\n# Make predictions\\ny_pred = model.predict(X_test)\\n\\n# Evaluate the model\\nmse = mean_squared_error(y_test, y_pred)\\nr2 = r2_score(y_test, y_pred)\\nprint(f'Mean Squared Error: {mse}')\\nprint(f'R-squared: {r2}')\\n```\\n\\nThis code assumes you have a CSV file named 'data.csv' with two columns: 'features' and 'target'. You can replace this with your own dataset. The code trains a linear regression model on the training data and evaluates its performance on the testing data using mean squared error and R-squared metrics.\" additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 585, 'prompt_tokens': 353, 'total_tokens': 938, 'completion_time': 2.127272727, 'prompt_time': 0.017899701, 'queue_time': 0.05147199899999999, 'total_time': 2.145172428}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_6507bcfb6f', 'finish_reason': 'stop', 'logprobs': None} id='run--d51ccb22-1e3f-4cae-a0bd-c0bd397883bb-0' usage_metadata={'input_tokens': 353, 'output_tokens': 585, 'total_tokens': 938}\n"
     ]
    }
   ],
   "source": [
    "question = \"write a python code to train linear regression model from taking data till predictions\"\n",
    "response = invoke_chain(question)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "Ga82r2aBofnV"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Data science is an interdisciplinary field that combines elements of computer science, statistics, and domain-specific knowledge to extract insights and knowledge from data. It involves using various techniques, such as machine learning, data visualization, and statistical modeling, to analyze and interpret complex data sets.\\n\\nData science typically involves the following steps:\\n\\n1. **Data collection**: Gathering data from various sources, such as databases, APIs, or files.\\n2. **Data preprocessing**: Cleaning, transforming, and formatting the data for analysis.\\n3. **Exploratory data analysis**: Visualizing and summarizing the data to understand its distribution, patterns, and relationships.\\n4. **Modeling**: Applying machine learning or statistical models to the data to make predictions, classify outcomes, or identify trends.\\n5. **Evaluation**: Assessing the performance of the models and refining them as needed.\\n6. **Deployment**: Implementing the models in a production environment to generate insights and inform decision-making.\\n\\nData science has numerous applications across industries, including business, healthcare, finance, and more. It requires a combination of technical skills, such as programming and data analysis, as well as domain expertise and communication skills to effectively interpret and present findings.\\n\\nSome key skills required for a career in data science include:\\n\\n* Programming languages like Python, R, or SQL\\n* Data visualization tools like Tableau, Power BI, or Matplotlib\\n* Machine learning frameworks like scikit-learn, TensorFlow, or PyTorch\\n* Statistical knowledge and data modeling techniques\\n* Communication and storytelling skills to present insights and results\\n\\nI hope this helps! Do you have any specific questions about data science or its applications?' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 331, 'prompt_tokens': 343, 'total_tokens': 674, 'completion_time': 1.203636364, 'prompt_time': 0.017301768, 'queue_time': 0.052881072, 'total_time': 1.2209381320000001}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_3f3b593e33', 'finish_reason': 'stop', 'logprobs': None} id='run--1b2aa0bf-6560-40ca-a03d-3e6be7c85418-0' usage_metadata={'input_tokens': 343, 'output_tokens': 331, 'total_tokens': 674}\n",
      "content=\"I'm excited to help you with your questions related to Data Science and Artificial Intelligence. Please go ahead and ask your question, and I'll do my best to provide a clear and concise answer. I'm here to help you understand concepts, tools, and techniques in Data Science and AI, and I look forward to our conversation. What's your question?\" additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 72, 'prompt_tokens': 339, 'total_tokens': 411, 'completion_time': 0.261818182, 'prompt_time': 0.017955542, 'queue_time': 0.058492901, 'total_time': 0.279773724}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_6507bcfb6f', 'finish_reason': 'stop', 'logprobs': None} id='run--cfafbbf5-b70d-45ed-9786-d1191b35a001-0' usage_metadata={'input_tokens': 339, 'output_tokens': 72, 'total_tokens': 411}\n",
      "content=\"I'm excited to help you with your questions related to Data Science and Artificial Intelligence. Please go ahead and ask your question, and I'll do my best to provide a clear and concise answer. I'm here to help you understand concepts, tools, and techniques in Data Science and AI, and I look forward to our conversation. What's your question?\" additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 72, 'prompt_tokens': 339, 'total_tokens': 411, 'completion_time': 0.435763777, 'prompt_time': 0.017101918, 'queue_time': 0.052285142, 'total_time': 0.452865695}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_6507bcfb6f', 'finish_reason': 'stop', 'logprobs': None} id='run--dacd74e1-211e-4b1f-8a2a-bc19a1c0cf4a-0' usage_metadata={'input_tokens': 339, 'output_tokens': 72, 'total_tokens': 411}\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCannot execute code, session has been disposed. Please try restarting the Kernel."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCannot execute code, session has been disposed. Please try restarting the Kernel. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    question = input(\"Ask a question (or type 'exit' to quit): \")\n",
    "    if question.lower() == 'exit':\n",
    "        break\n",
    "\n",
    "    response = invoke_chain(question)\n",
    "    print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNixWR3imGiPaPLD/71sALg",
   "mount_file_id": "1j2D-q6AWY1AXCSv7B-Qj5sEeiQeAzo9X",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "chatbot-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
